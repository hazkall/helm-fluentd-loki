kind: "DaemonSet"

## Labels to be added to fluentd DaemonSet/Deployment
##

image:
  repository: "fluent/fluentd-kubernetes-daemonset"
  pullPolicy: "IfNotPresent"
  tag: "v1.4-debian-forward-1"

## Optional array of imagePullSecrets containing private registry credentials
## Ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/
imagePullSecrets: []

labels: {}

nodeSelector: {}

## Node tolerations for server scheduling to nodes with taints
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/
##
tolerations: []
# - key: null
#   operator: Exists
#   effect: "NoSchedule"

## Affinity and anti-affinity
## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
##
affinity: {}

## Annotations to be added to fluentd daemonset
##
annotations: {}

## Annotations to be added to fluentd pod
##
podAnnotations: {}

## Deployment strategy / DaemonSet updateStrategy
##
updateStrategy: {}
#   type: RollingUpdate
#   rollingUpdate:
#     maxUnavailable: 1

serviceAccount:
  create: true
  annotations: {}
  name: null

rbac:
  create: true

# Configure podsecuritypolicy
# Ref: https://kubernetes.io/docs/concepts/policy/pod-security-policy/
podSecurityPolicy:
  enabled: true
  annotations: {}

podSecurityContext: {}
  # seLinuxOptions:
  #   type: "spc_t"

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

# Configure the livessProbe
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
livenessProbe:
  httpGet:
    path: /metrics
    port: metrics
  # initialDelaySeconds: 0
  # periodSeconds: 10
  # timeoutSeconds: 1
  # successThreshold: 1
  # failureThreshold: 3

# Configure the readinessProbe
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
readinessProbe:
  httpGet:
    path: /metrics
    port: metrics
  # initialDelaySeconds: 0
  # periodSeconds: 10
  # timeoutSeconds: 1
  # successThreshold: 1
  # failureThreshold: 3

resources: {}
  # requests:
  #   cpu: 10m
  #   memory: 128Mi
  # limits:
  #   memory: 128Mi

## Fluentd service
##
service:
  type: "ClusterIP"
  annotations: {}
  ports: []
  # - name: "forwarder"
  #   protocol: TCP
  #   containerPort: 24224

env:
- name: "FLUENTD_CONF"
  value: "fluent.conf"
- name: "LOKI_URL"
  value: "http://loki-server:3100"
- name: "LOKI_USERNAME"
  value: ""
- name: "LOKI_PASSWORD"
  value: ""

envFrom: []

volumes:
  - name: varlog
    hostPath:
      path: /var/log

  - name: varlibdockercontainers
    hostPath:
      path: /var/lib/docker/containers

  - name: etcfluentd-config
    configMap:
      name: fluentd-config
      defaultMode: 511

volumeMounts:
  - name: varlog
    mountPath: /var/log

  - name: varlibdockercontainers
    readOnly: true
    mountPath: /var/lib/docker/containers

  - name: etcfluentd-config
    mountPath: /fluentd/etc

## Fluentd list of plugins to install
##
plugins: []
# - fluent-plugin-out-http

# Fluentd Configuration files
fileConfigs:
  fluent.conf: |-
    ################################################################
    # This source gets all logs from local container runtime host
    @include pods-fluent.conf
    @include prometheus.conf
    @include loki-fluent.conf

  pods-fluent.conf: |-
    <source>
      @type tail
      @id in_tail_container_logs
      read_from_head true
      tag kubernetes.*
      path /var/log/containers/*.log
      pos_file /var/log/fluentd-containers.log.pos
      exclude_path ["/var/log/containers/fluent*"]
      <parse>
        @type multi_format
        <pattern>
          format json
          time_key time
          time_type string
          time_format "%Y-%m-%dT%H:%M:%S.%NZ"
          keep_time_key false
        </pattern>
        <pattern>
          format regexp
          expression /^(?<time>.+) (?<stream>stdout|stderr)( (.))? (?<log>.*)$/
          time_format '%Y-%m-%dT%H:%M:%S.%NZ'
          keep_time_key false
        </pattern>
      </parse>
      emit_unmatched_lines true
    </source>

    <match fluentd.**>
      @type null
    </match>

    <match kubernetes.var.log.containers.**fluentd**.log>
      @type null
    </match>

    <filter kubernetes.**>
      @type kubernetes_metadata
      @id filter_kube_metadata
      kubernetes_url "#{'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}"
      verify_ssl "true"
      ca_file "#{ENV['KUBERNETES_CA_FILE']}"
    </filter>

    <filter kubernetes.**>
      @type parser
      key_name log
      <parse>
        @type json
        json_parser json
      </parse>
      replace_invalid_sequence true
      reserve_data true # this preserves unparsable log lines
      emit_invalid_record_to_error false # In case of unparsable log lines keep the error log clean
      reserve_time # the time was already parsed in the source, we don't want to overwrite it with current time.
    </filter>

    <filter kubernetes.var.log.containers.**>
      @type record_transformer
      enable_ruby
      remove_keys kubernetes, docker

      <record>
        #app ${ record.dig("kubernetes", "labels", "app") }
        namespace ${ record.dig("kubernetes", "namespace_name") }
        pod ${ record.dig("kubernetes", "pod_name") }
        container ${ record.dig("kubernetes", "container_name") }
      </record>

    </filter>

  prometheus.conf: |-
    <source>
      @type prometheus
      @id in_prometheus
      bind "0.0.0.0"
      port 24231
      metrics_path "/metrics"
    </source>

  loki-fluent.conf: |-
    <match kubernetes.**>
      @type loki
      url "#{ENV['LOKI_URL']}"
      username "#{ENV['LOKI_USERNAME']}"
      password "#{ENV['LOKI_PASSWORD']}"
      extract_kubernetes_labels true
      label_keys "namespace,pod,container"
      extra_labels {"collector":"fluentd"}
      flush_interval 10s
      flush_at_shutdown true
      buffer_chunk_limit 1m
      line_format key_value
    </match>
